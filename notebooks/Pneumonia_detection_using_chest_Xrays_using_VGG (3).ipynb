{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHFnBP0Sq9yX"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip -q install torch torchvision torchaudio --upgrade\n",
        "!pip -q install scikit-learn matplotlib pillow tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-35iQiB_rSHY"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATASET_DIR = \"/content/drive/MyDrive/chest_xray\"\n",
        "\n",
        "import os, glob, random, shutil\n",
        "assert os.path.exists(DATASET_DIR), f\"Path not found: {DATASET_DIR}\"\n",
        "print(\"Drive dataset root:\", DATASET_DIR)\n",
        "ROOT = DATASET_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiA0UrXssP2A"
      },
      "outputs": [],
      "source": [
        "import os, glob, random, shutil\n",
        "\n",
        "def has_split(root):\n",
        "    return all(os.path.isdir(os.path.join(root, s)) for s in [\"train\",\"val\",\"test\"])\n",
        "\n",
        "if not has_split(ROOT):\n",
        "    if all(os.path.isdir(os.path.join(ROOT, s)) for s in [\"train\",\"test\"]):\n",
        "        val_dir = os.path.join(ROOT, \"val\")\n",
        "        os.makedirs(val_dir, exist_ok=True)\n",
        "        for cls in os.listdir(os.path.join(ROOT, \"train\")):\n",
        "            src = os.path.join(ROOT, \"train\", cls)\n",
        "            dst = os.path.join(val_dir, cls)\n",
        "            os.makedirs(dst, exist_ok=True)\n",
        "            files = [f for f in glob.glob(os.path.join(src, \"*\")) if os.path.isfile(f)]\n",
        "            random.shuffle(files)\n",
        "            take = max(1, int(0.1*len(files)))\n",
        "            for f in files[:take]:\n",
        "                shutil.copy2(f, os.path.join(dst, os.path.basename(f)))\n",
        "        print(\"Created validation split on Drive (copied ~10% from train).\")\n",
        "    else:\n",
        "\n",
        "        classes = [d for d in os.listdir(ROOT) if os.path.isdir(os.path.join(ROOT, d))]\n",
        "        if classes:\n",
        "            print(\"Creating 80/10/10 split from flat class folders on Drive (copying files)...\")\n",
        "            split_root = os.path.join(ROOT, \"_split\")\n",
        "            for split in [\"train\",\"val\",\"test\"]:\n",
        "                for cls in classes:\n",
        "                    os.makedirs(os.path.join(split_root, split, cls), exist_ok=True)\n",
        "            for cls in classes:\n",
        "                files = [f for f in glob.glob(os.path.join(ROOT, cls, \"*\")) if os.path.isfile(f)]\n",
        "                random.shuffle(files)\n",
        "                n = len(files); n_train = int(0.8*n); n_val = int(0.1*n)\n",
        "                for i,f in enumerate(files):\n",
        "                    if i < n_train:\n",
        "                        dst = os.path.join(split_root, \"train\", cls, os.path.basename(f))\n",
        "                    elif i < n_train + n_val:\n",
        "                        dst = os.path.join(split_root, \"val\", cls, os.path.basename(f))\n",
        "                    else:\n",
        "                        dst = os.path.join(split_root, \"test\", cls, os.path.basename(f))\n",
        "                    shutil.copy2(f, dst)\n",
        "            ROOT = split_root\n",
        "\n",
        "print(\"Using dataset root with splits:\", ROOT)\n",
        "!find \"$ROOT\" -maxdepth 2 -type d -print\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Oc67Ze-sYn9"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch, os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(os.path.join(ROOT, \"train\"), transform=train_tfms)\n",
        "val_ds   = datasets.ImageFolder(os.path.join(ROOT, \"val\"),   transform=val_tfms)\n",
        "test_ds  = datasets.ImageFolder(os.path.join(ROOT, \"test\"),  transform=val_tfms)\n",
        "\n",
        "num_workers = 0\n",
        "pin_memory = False\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "class_names = train_ds.classes\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "len(train_ds), len(val_ds), len(test_ds), class_names, DEVICE\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from collections import Counter\n",
        "\n",
        "targets = [y for _, y in train_ds.samples]\n",
        "counts = Counter(targets)\n",
        "num_classes = len(class_names)\n",
        "total = sum(counts.values())\n",
        "class_weights = torch.zeros(num_classes, dtype=torch.float)\n",
        "for c in range(num_classes):\n",
        "    class_weights[c] = total / (num_classes * counts[c])\n",
        "print(\"Class counts:\", counts)\n",
        "print(\"Class weights:\", class_weights)\n"
      ],
      "metadata": {
        "id": "sPA3XnPP44tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torchvision import models\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "\n",
        "PROJECT_NAME = \"pneumonia_vgg_colab\"\n",
        "DRIVE_DIR = f\"/content/drive/MyDrive/{PROJECT_NAME}\"\n",
        "os.makedirs(DRIVE_DIR, exist_ok=True)\n",
        "\n",
        "ARCH = \"vgg16\"\n",
        "LR = 1e-3\n",
        "WD = 1e-4\n",
        "FREEZE_FEATURES_EPOCHS = 1\n",
        "EPOCHS = 8\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "if ARCH == \"vgg16\":\n",
        "    model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
        "else:\n",
        "    model = models.vgg19(weights=models.VGG19_Weights.DEFAULT)\n",
        "\n",
        "in_features = model.classifier[-1].in_features\n",
        "model.classifier[-1] = nn.Linear(in_features, len(class_names))\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(DEVICE))\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "if FREEZE_FEATURES_EPOCHS > 0:\n",
        "    for p in model.features.parameters():\n",
        "        p.requires_grad = False\n",
        "print(\"Features frozen for first\", FREEZE_FEATURES_EPOCHS, \"epochs\")\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
        "\n",
        "best_val_acc = 0.0\n",
        "history = {\"train_loss\":[], \"val_acc\":[]}\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} - train\"):\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running += loss.item() * images.size(0)\n",
        "    train_loss = running / len(train_loader.dataset)\n",
        "\n",
        "    if epoch == FREEZE_FEATURES_EPOCHS:\n",
        "        for p in model.parameters(): p.requires_grad = True\n",
        "        print(\"Unfroze all layers.\")\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0; total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch}/{EPOCHS} - val\"):\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
        "                outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    val_acc = correct / total if total>0 else 0.0\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f} val_acc={val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), os.path.join(DRIVE_DIR, f\"best_{ARCH}.pth\"))\n",
        "        print(\"Saved new best model to Drive.\")\n",
        "\n",
        "print(\"Best val acc:\", best_val_acc)\n"
      ],
      "metadata": {
        "id": "AL6uDg0q47tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt, numpy as np, torch, os\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import itertools\n",
        "\n",
        "plt.figure(); plt.plot(history[\"train_loss\"], label=\"train_loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Training Loss\"); plt.legend()\n",
        "plt.savefig(os.path.join(DRIVE_DIR,\"training_loss.png\")); plt.show()\n",
        "\n",
        "plt.figure(); plt.plot(history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Validation Accuracy\"); plt.legend()\n",
        "plt.savefig(os.path.join(DRIVE_DIR,\"val_accuracy.png\")); plt.show()\n",
        "\n",
        "state_dict_path = os.path.join(DRIVE_DIR, f\"best_{ARCH}.pth\")\n",
        "model.load_state_dict(torch.load(state_dict_path, map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "all_labels, all_preds, all_probs = [], [], []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
        "            outputs = model(images)\n",
        "        probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "        all_labels.extend(labels.numpy())\n",
        "        all_preds.extend(preds)\n",
        "        if len(class_names)==2:\n",
        "            all_probs.extend(probs[:,1])\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\\\\n\", cm)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation='nearest'); plt.title('Confusion matrix'); plt.colorbar()\n",
        "ticks = np.arange(len(class_names))\n",
        "plt.xticks(ticks, class_names, rotation=45); plt.yticks(ticks, class_names)\n",
        "thr = cm.max()/2.\n",
        "for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, f\"{cm[i,j]}\", ha=\"center\", va=\"center\",\n",
        "             color=\"white\" if cm[i,j] > thr else \"black\")\n",
        "plt.ylabel('True label'); plt.xlabel('Predicted label'); plt.tight_layout()\n",
        "plt.savefig(os.path.join(DRIVE_DIR,\"confusion_matrix.png\")); plt.show()\n",
        "\n",
        "if len(class_names)==2 and len(all_probs)==len(all_labels):\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
        "    print(\"ROC AUC:\", auc)\n",
        "    plt.figure(); plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\"); plt.plot([0,1],[0,1],'--')\n",
        "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC Curve\"); plt.legend(loc=\"lower right\")\n",
        "    plt.savefig(os.path.join(DRIVE_DIR,\"roc_curve.png\")); plt.show()\n"
      ],
      "metadata": {
        "id": "CeaUwSl85Uqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q95ZoEJvaVOj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}