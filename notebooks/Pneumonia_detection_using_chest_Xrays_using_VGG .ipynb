{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHFnBP0Sq9yX"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip -q install torch torchvision torchaudio --upgrade\n",
        "!pip -q install scikit-learn matplotlib pillow tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-35iQiB_rSHY"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATASET_DIR = \"/content/drive/MyDrive/chest_xray\"\n",
        "\n",
        "import os, glob, random, shutil\n",
        "assert os.path.exists(DATASET_DIR), f\"Path not found: {DATASET_DIR}\"\n",
        "print(\"Drive dataset root:\", DATASET_DIR)\n",
        "ROOT = DATASET_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiA0UrXssP2A"
      },
      "outputs": [],
      "source": [
        "import os, glob, random, shutil\n",
        "\n",
        "def has_split(root):\n",
        "    return all(os.path.isdir(os.path.join(root, s)) for s in [\"train\",\"val\",\"test\"])\n",
        "\n",
        "if not has_split(ROOT):\n",
        "    if all(os.path.isdir(os.path.join(ROOT, s)) for s in [\"train\",\"test\"]):\n",
        "        val_dir = os.path.join(ROOT, \"val\")\n",
        "        os.makedirs(val_dir, exist_ok=True)\n",
        "        for cls in os.listdir(os.path.join(ROOT, \"train\")):\n",
        "            src = os.path.join(ROOT, \"train\", cls)\n",
        "            dst = os.path.join(val_dir, cls)\n",
        "            os.makedirs(dst, exist_ok=True)\n",
        "            files = [f for f in glob.glob(os.path.join(src, \"*\")) if os.path.isfile(f)]\n",
        "            random.shuffle(files)\n",
        "            take = max(1, int(0.1*len(files)))\n",
        "            for f in files[:take]:\n",
        "                shutil.copy2(f, os.path.join(dst, os.path.basename(f)))\n",
        "        print(\"Created validation split on Drive (copied ~10% from train).\")\n",
        "    else:\n",
        "\n",
        "        classes = [d for d in os.listdir(ROOT) if os.path.isdir(os.path.join(ROOT, d))]\n",
        "        if classes:\n",
        "            print(\"Creating 80/10/10 split from flat class folders on Drive (copying files)...\")\n",
        "            split_root = os.path.join(ROOT, \"_split\")\n",
        "            for split in [\"train\",\"val\",\"test\"]:\n",
        "                for cls in classes:\n",
        "                    os.makedirs(os.path.join(split_root, split, cls), exist_ok=True)\n",
        "            for cls in classes:\n",
        "                files = [f for f in glob.glob(os.path.join(ROOT, cls, \"*\")) if os.path.isfile(f)]\n",
        "                random.shuffle(files)\n",
        "                n = len(files); n_train = int(0.8*n); n_val = int(0.1*n)\n",
        "                for i,f in enumerate(files):\n",
        "                    if i < n_train:\n",
        "                        dst = os.path.join(split_root, \"train\", cls, os.path.basename(f))\n",
        "                    elif i < n_train + n_val:\n",
        "                        dst = os.path.join(split_root, \"val\", cls, os.path.basename(f))\n",
        "                    else:\n",
        "                        dst = os.path.join(split_root, \"test\", cls, os.path.basename(f))\n",
        "                    shutil.copy2(f, dst)\n",
        "            ROOT = split_root\n",
        "\n",
        "print(\"Using dataset root with splits:\", ROOT)\n",
        "!find \"$ROOT\" -maxdepth 2 -type d -print\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Oc67Ze-sYn9"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch, os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(os.path.join(ROOT, \"train\"), transform=train_tfms)\n",
        "val_ds   = datasets.ImageFolder(os.path.join(ROOT, \"val\"),   transform=val_tfms)\n",
        "test_ds  = datasets.ImageFolder(os.path.join(ROOT, \"test\"),  transform=val_tfms)\n",
        "\n",
        "num_workers = 0\n",
        "pin_memory = False\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "class_names = train_ds.classes\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "len(train_ds), len(val_ds), len(test_ds), class_names, DEVICE\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from collections import Counter\n",
        "\n",
        "targets = [y for _, y in train_ds.samples]\n",
        "counts = Counter(targets)\n",
        "num_classes = len(class_names)\n",
        "total = sum(counts.values())\n",
        "class_weights = torch.zeros(num_classes, dtype=torch.float)\n",
        "for c in range(num_classes):\n",
        "    class_weights[c] = total / (num_classes * counts[c])\n",
        "print(\"Class counts:\", counts)\n",
        "print(\"Class weights:\", class_weights)\n"
      ],
      "metadata": {
        "id": "sPA3XnPP44tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torchvision import models\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "\n",
        "PROJECT_NAME = \"pneumonia_vgg_colab\"\n",
        "DRIVE_DIR = f\"/content/drive/MyDrive/{PROJECT_NAME}\"\n",
        "os.makedirs(DRIVE_DIR, exist_ok=True)\n",
        "\n",
        "ARCH = \"vgg16\"\n",
        "LR = 1e-3\n",
        "WD = 1e-4\n",
        "FREEZE_FEATURES_EPOCHS = 1\n",
        "EPOCHS = 8\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "if ARCH == \"vgg16\":\n",
        "    model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
        "else:\n",
        "    model = models.vgg19(weights=models.VGG19_Weights.DEFAULT)\n",
        "\n",
        "in_features = model.classifier[-1].in_features\n",
        "model.classifier[-1] = nn.Linear(in_features, len(class_names))\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(DEVICE))\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "if FREEZE_FEATURES_EPOCHS > 0:\n",
        "    for p in model.features.parameters():\n",
        "        p.requires_grad = False\n",
        "print(\"Features frozen for first\", FREEZE_FEATURES_EPOCHS, \"epochs\")\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
        "\n",
        "best_val_acc = 0.0\n",
        "history = {\"train_loss\":[], \"val_acc\":[]}\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} - train\"):\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running += loss.item() * images.size(0)\n",
        "    train_loss = running / len(train_loader.dataset)\n",
        "\n",
        "    if epoch == FREEZE_FEATURES_EPOCHS:\n",
        "        for p in model.parameters(): p.requires_grad = True\n",
        "        print(\"Unfroze all layers.\")\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0; total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch}/{EPOCHS} - val\"):\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
        "                outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    val_acc = correct / total if total>0 else 0.0\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f} val_acc={val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), os.path.join(DRIVE_DIR, f\"best_{ARCH}.pth\"))\n",
        "        print(\"Saved new best model to Drive.\")\n",
        "\n",
        "print(\"Best val acc:\", best_val_acc)\n"
      ],
      "metadata": {
        "id": "AL6uDg0q47tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt, numpy as np, torch, os\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import itertools\n",
        "import os\n",
        "os.makedirs(DRIVE_DIR, exist_ok=True)\n",
        "plt.figure(); plt.plot(history[\"train_loss\"], label=\"train_loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Training Loss\"); plt.legend()\n",
        "plt.savefig(os.path.join(DRIVE_DIR,\"training_loss.png\")); plt.show()\n",
        "\n",
        "plt.figure(); plt.plot(history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Validation Accuracy\"); plt.legend()\n",
        "plt.savefig(os.path.join(DRIVE_DIR,\"val_accuracy.png\")); plt.show()\n",
        "\n",
        "state_dict_path = os.path.join(DRIVE_DIR, f\"best_{ARCH}.pth\")\n",
        "model.load_state_dict(torch.load(state_dict_path, map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "all_labels, all_preds, all_probs = [], [], []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
        "            outputs = model(images)\n",
        "        probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "        all_labels.extend(labels.numpy())\n",
        "        all_preds.extend(preds)\n",
        "        if len(class_names)==2:\n",
        "            all_probs.extend(probs[:,1])\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\\\\n\", cm)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation='nearest'); plt.title('Confusion matrix'); plt.colorbar()\n",
        "ticks = np.arange(len(class_names))\n",
        "plt.xticks(ticks, class_names, rotation=45); plt.yticks(ticks, class_names)\n",
        "thr = cm.max()/2.\n",
        "for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, f\"{cm[i,j]}\", ha=\"center\", va=\"center\",\n",
        "             color=\"white\" if cm[i,j] > thr else \"black\")\n",
        "plt.ylabel('True label'); plt.xlabel('Predicted label'); plt.tight_layout()\n",
        "plt.savefig(os.path.join(DRIVE_DIR,\"confusion_matrix.png\")); plt.show()\n",
        "\n",
        "if len(class_names)==2 and len(all_probs)==len(all_labels):\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
        "    print(\"ROC AUC:\", auc)\n",
        "    plt.figure(); plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\"); plt.plot([0,1],[0,1],'--')\n",
        "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC Curve\"); plt.legend(loc=\"lower right\")\n",
        "    plt.savefig(os.path.join(DRIVE_DIR,\"roc_curve.png\")); plt.show()\n"
      ],
      "metadata": {
        "id": "CeaUwSl85Uqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image, ImageFilter, ImageEnhance\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def pil_from_tensor(x):\n",
        "    # x: (C,H,W) in [0,1]\n",
        "    x = x.clone().cpu()\n",
        "    np_img = np.transpose(x.numpy(), (1, 2, 0))\n",
        "    np_img = np.clip(np_img, 0, 1)\n",
        "    return Image.fromarray((np_img * 255).astype(np.uint8))\n",
        "\n",
        "def apply_perturbation(img_pil, kind, severity):\n",
        "    img = img_pil.copy()\n",
        "    if kind == \"gaussian_noise\":\n",
        "        np_img = np.array(img)/255.0\n",
        "        noise = np.random.normal(0, severity, np_img.shape)\n",
        "        np_img = np.clip(np_img + noise, 0, 1)\n",
        "        img = Image.fromarray((np_img*255).astype(np.uint8))\n",
        "    elif kind == \"blur\":\n",
        "        img = img.filter(ImageFilter.GaussianBlur(radius=severity))\n",
        "    elif kind == \"brightness\":\n",
        "        enhancer = ImageEnhance.Brightness(img)\n",
        "        img = enhancer.enhance(severity)  # <1 darker, >1 brighter\n",
        "    elif kind == \"rotation\":\n",
        "        img = img.rotate(severity)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "i_wdpzKoyYdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "all_clean_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        outputs = model(images)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "        preds = probs.argmax(dim=1)\n",
        "        all_clean_preds.append(preds.cpu())\n",
        "\n",
        "all_clean_preds = torch.cat(all_clean_preds)\n",
        "print(\"Collected baseline predictions for\", len(all_clean_preds), \"test samples\")\n"
      ],
      "metadata": {
        "id": "8KEF2FzLyZu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "base_tfms = val_tfms\n",
        "\n",
        "perturbation_configs = [\n",
        "    (\"none\",           None,            0),\n",
        "    (\"gaussian_noise\", \"gaussian_noise\", 0.05),\n",
        "    (\"gaussian_noise\", \"gaussian_noise\", 0.10),\n",
        "    (\"blur\",           \"blur\",          2),\n",
        "    (\"brightness\",     \"brightness\",    0.5),\n",
        "    (\"brightness\",     \"brightness\",    1.5),\n",
        "    (\"rotation\",       \"rotation\",      5),\n",
        "]\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, kind, severity in perturbation_configs:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    changed = 0\n",
        "    idx_global = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=f\"Perturbation: {name}-{severity}\"):\n",
        "            bs = images.size(0)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            pil_imgs = []\n",
        "            for i in range(bs):\n",
        "                img = images[i].cpu()\n",
        "                # unnormalize\n",
        "                mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
        "                std  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
        "                img_unnorm = img * std + mean\n",
        "                pil = pil_from_tensor(img_unnorm)\n",
        "                if kind is not None:\n",
        "                    pil = apply_perturbation(pil, kind, severity)\n",
        "                pil_imgs.append(pil)\n",
        "\n",
        "            pert_tensors = torch.stack([base_tfms(p) for p in pil_imgs]).to(DEVICE)\n",
        "\n",
        "            outputs = model(pert_tensors)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            preds = probs.argmax(dim=1)\n",
        "\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += bs\n",
        "\n",
        "            clean_batch = all_clean_preds[idx_global:idx_global+bs]\n",
        "            changed += (preds.cpu() != clean_batch).sum().item()\n",
        "            idx_global += bs\n",
        "\n",
        "    acc = correct / total\n",
        "    flip_rate = changed / total\n",
        "    results[(name, severity)] = (acc, flip_rate)\n",
        "    print(f\"{name} (sev={severity}): accuracy={acc:.3f}, flip rate={flip_rate:.3f}\")\n"
      ],
      "metadata": {
        "id": "tVWVrfNUyZyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== VGG Robustness Summary ===\")\n",
        "print(\"Perturbation\\tSeverity\\tAccuracy\\tFlipRate\")\n",
        "for (name, sev), (acc, flip) in results.items():\n",
        "    print(f\"{name}\\t{sev}\\t{acc:.3f}\\t{flip:.3f}\")\n"
      ],
      "metadata": {
        "id": "Ke89yeJ8yZ2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grad-cam\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "Hwjxjh2JyZ5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_layer = model.features[-1]  # for VGG\n",
        "def gradcam_on_image_vgg(img_path, target_class_idx=None):\n",
        "    # Load and preprocess image\n",
        "    img_pil = Image.open(img_path).convert(\"RGB\")\n",
        "    img_resized = img_pil.resize((224, 224))\n",
        "    rgb_img = np.array(img_resized) / 255.0\n",
        "\n",
        "    input_tensor = base_tfms(img_pil).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    # Get prediction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(input_tensor)\n",
        "        pred_idx = out.argmax(dim=1).item()\n",
        "\n",
        "    class_idx = target_class_idx if target_class_idx is not None else pred_idx\n",
        "\n",
        "    # Run Grad-CAM\n",
        "    with GradCAM(model=model, target_layers=[target_layer]) as cam:\n",
        "        grayscale_cam = cam(\n",
        "            input_tensor=input_tensor,\n",
        "            targets=[ClassifierOutputTarget(class_idx)]\n",
        "        )[0]   # [H,W]\n",
        "\n",
        "    cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(6,3))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img_pil)\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(cam_image)\n",
        "    plt.title(f\"Grad-CAM: {CLASS_NAMES[class_idx]}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return pred_idx, class_idx, grayscale_cam\n"
      ],
      "metadata": {
        "id": "C-3GjFgKyZ9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import os\n",
        "\n",
        "DATASET_DIR = \"/content/drive/MyDrive/chest_xray\"   # adjust if yours differs\n",
        "\n",
        "test_ds = datasets.ImageFolder(os.path.join(DATASET_DIR, \"test\"))\n",
        "CLASS_NAMES = test_ds.classes\n",
        "print(\"CLASS NAMES:\", CLASS_NAMES)\n"
      ],
      "metadata": {
        "id": "bKiA2r7vMr0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/drive/MyDrive/chest_xray/test/PNEUMONIA/person1_virus_6.jpeg\"\n",
        "pred_idx, class_idx, grayscale_cam = gradcam_on_image_vgg(img_path)\n",
        "print(\"Model predicted:\", CLASS_NAMES[pred_idx])\n"
      ],
      "metadata": {
        "id": "1P6Ekc8OynuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def central_focus_score(grayscale_cam, central_frac=0.5):\n",
        "    h, w = grayscale_cam.shape\n",
        "    ch = int(h * central_frac)\n",
        "    cw = int(w * central_frac)\n",
        "    y0 = (h - ch)//2\n",
        "    x0 = (w - cw)//2\n",
        "\n",
        "    central = grayscale_cam[y0:y0+ch, x0:x0+cw]\n",
        "    total = grayscale_cam.sum() + 1e-8\n",
        "    return central.sum() / total\n"
      ],
      "metadata": {
        "id": "Zs5zyQg0yp_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = central_focus_score(grayscale_cam, central_frac=0.5)\n",
        "print(\"Central focus score:\", score)\n"
      ],
      "metadata": {
        "id": "Y-iTbReJyqC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "test_ds = test_loader.dataset   # from ImageFolder\n",
        "CLASS_NAMES = test_ds.classes\n",
        "print(\"Classes:\", CLASS_NAMES)\n",
        "\n",
        "random.seed(42)\n",
        "num_samples = 60\n",
        "indices = random.sample(range(len(test_ds)), num_samples)\n",
        "\n",
        "scores_vgg = {\n",
        "    \"normal_correct\": [],\n",
        "    \"pneumonia_correct\": [],\n",
        "    \"misclassified\": []\n",
        "}\n",
        "\n",
        "for idx in indices:\n",
        "    img_path, true_label = test_ds.samples[idx]\n",
        "\n",
        "    pred_idx, class_idx, grayscale_cam = gradcam_on_image_vgg(img_path)\n",
        "    score = central_focus_score(grayscale_cam, central_frac=0.5)\n",
        "\n",
        "    if pred_idx == true_label:\n",
        "        if CLASS_NAMES[true_label].upper() == \"NORMAL\":\n",
        "            scores_vgg[\"normal_correct\"].append(score)\n",
        "        else:\n",
        "            scores_vgg[\"pneumonia_correct\"].append(score)\n",
        "    else:\n",
        "        scores_vgg[\"misclassified\"].append(score)\n"
      ],
      "metadata": {
        "id": "sdRiz2b7yqGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def mean_or_nan(x):\n",
        "    return float(np.mean(x)) if len(x) > 0 else float(\"nan\")\n",
        "\n",
        "normal_mean = mean_or_nan(scores_vgg[\"normal_correct\"])\n",
        "pneu_mean   = mean_or_nan(scores_vgg[\"pneumonia_correct\"])\n",
        "mis_mean    = mean_or_nan(scores_vgg[\"misclassified\"])\n",
        "\n",
        "print(\"=== VGG Grad-CAM Central Focus Summary ===\")\n",
        "print(f\"Correct NORMAL      (n={len(scores_vgg['normal_correct'])}):   {normal_mean:.3f}\")\n",
        "print(f\"Correct PNEUMONIA   (n={len(scores_vgg['pneumonia_correct'])}): {pneu_mean:.3f}\")\n",
        "print(f\"Misclassified       (n={len(scores_vgg['misclassified'])}):     {mis_mean:.3f}\")\n"
      ],
      "metadata": {
        "id": "vhZYGoKPywm7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}