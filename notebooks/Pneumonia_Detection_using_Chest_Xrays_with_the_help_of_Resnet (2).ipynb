{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import imageio"
      ],
      "metadata": {
        "id": "frOIQ0_u3HG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATASET_DIR = \"/content/drive/MyDrive/chest_xray\"\n",
        "\n",
        "import os, shutil, random, glob, zipfile, pathlib\n",
        "from pathlib import Path\n",
        "\n",
        "assert os.path.exists(DATASET_DIR), f\"Path not found: {DATASET_DIR}\"\n",
        "print(\"Using dataset root:\", DATASET_DIR)\n"
      ],
      "metadata": {
        "id": "7Fttm3m93Kl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile, glob, random, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def maybe_unzip(root):\n",
        "    zips = glob.glob(os.path.join(root, \"*.zip\"))\n",
        "    if zips:\n",
        "        for z in zips:\n",
        "            print(\"Unzipping:\", z)\n",
        "            with zipfile.ZipFile(z, 'r') as zip_ref:\n",
        "                zip_ref.extractall(root)\n",
        "\n",
        "maybe_unzip(DATASET_DIR)\n",
        "candidates = [\n",
        "    DATASET_DIR,\n",
        "    os.path.join(DATASET_DIR, \"chest_xray\"),\n",
        "]\n",
        "\n",
        "def has_split(root):\n",
        "    return all(os.path.isdir(os.path.join(root, s)) for s in [\"train\",\"val\",\"test\"])\n",
        "\n",
        "ROOT = None\n",
        "for c in candidates:\n",
        "    if has_split(c):\n",
        "        ROOT = c\n",
        "        break\n",
        "\n",
        "if ROOT is None:\n",
        "    for c in candidates:\n",
        "        if all(os.path.isdir(os.path.join(c, s)) for s in [\"train\",\"test\"]):\n",
        "            ROOT = c\n",
        "            val_dir = os.path.join(ROOT, \"val\")\n",
        "            os.makedirs(val_dir, exist_ok=True)\n",
        "            for cls in os.listdir(os.path.join(ROOT, \"train\")):\n",
        "                src = os.path.join(ROOT, \"train\", cls)\n",
        "                dst = os.path.join(val_dir, cls)\n",
        "                os.makedirs(dst, exist_ok=True)\n",
        "                files = [f for f in glob.glob(os.path.join(src, \"*\")) if os.path.isfile(f)]\n",
        "                random.shuffle(files)\n",
        "                take = max(1, int(0.1*len(files)))\n",
        "                for f in files[:take]:\n",
        "                    shutil.move(f, os.path.join(dst, os.path.basename(f)))\n",
        "            break\n",
        "\n",
        "if ROOT is None:\n",
        "    classes = [d for d in os.listdir(DATASET_DIR) if os.path.isdir(os.path.join(DATASET_DIR, d))]\n",
        "    if set(map(str.lower, classes)) >= {\"normal\",\"pneumonia\"}:\n",
        "        ROOT = os.path.join(DATASET_DIR, \"_split\")\n",
        "        if not os.path.exists(ROOT):\n",
        "            print(\"Creating train/val/test splits (80/10/10) from flat class folders...\")\n",
        "            for split in [\"train\",\"val\",\"test\"]:\n",
        "                for cls in classes:\n",
        "                    os.makedirs(os.path.join(ROOT, split, cls), exist_ok=True)\n",
        "            for cls in classes:\n",
        "                files = [f for f in glob.glob(os.path.join(DATASET_DIR, cls, \"*\")) if os.path.isfile(f)]\n",
        "                random.shuffle(files)\n",
        "                n = len(files)\n",
        "                n_train = int(0.8*n); n_val = int(0.1*n)\n",
        "                for i,f in enumerate(files):\n",
        "                    if i < n_train:\n",
        "                        dst = os.path.join(ROOT, \"train\", cls, os.path.basename(f))\n",
        "                    elif i < n_train + n_val:\n",
        "                        dst = os.path.join(ROOT, \"val\", cls, os.path.basename(f))\n",
        "                    else:\n",
        "                        dst = os.path.join(ROOT, \"test\", cls, os.path.basename(f))\n",
        "                    shutil.copy2(f, dst)\n",
        "\n",
        "assert ROOT is not None, \"Could not detect a valid dataset structure. Ensure folders are one of the expected layouts.\"\n",
        "print(\"Detected dataset root with splits:\", ROOT)\n",
        "!find \"$ROOT\" -maxdepth 2 -type d -print\n"
      ],
      "metadata": {
        "id": "gFb862RO9sLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(os.path.join(ROOT,\"train\"), transform=train_tfms)\n",
        "val_ds   = datasets.ImageFolder(os.path.join(ROOT,\"val\"),   transform=val_tfms)\n",
        "test_ds  = datasets.ImageFolder(os.path.join(ROOT,\"test\"),  transform=val_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "class_names = train_ds.classes\n",
        "len(train_ds), len(val_ds), len(test_ds), class_names\n"
      ],
      "metadata": {
        "id": "h1ideEdY91Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from collections import Counter\n",
        "\n",
        "targets = [y for _, y in train_ds.samples]\n",
        "counts = Counter(targets)\n",
        "num_classes = len(class_names)\n",
        "total = sum(counts.values())\n",
        "class_weights = torch.zeros(num_classes, dtype=torch.float)\n",
        "for c in range(num_classes):\n",
        "    class_weights[c] = total / (num_classes * counts[c])\n",
        "print(\"Class counts:\", counts)\n",
        "print(\"Class weights:\", class_weights)\n"
      ],
      "metadata": {
        "id": "Ui9CD1Qr94ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torchvision import models\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "\n",
        "PROJECT_NAME = \"pneumonia_resnet_colab\"\n",
        "DRIVE_DIR = f\"/content/drive/MyDrive/{PROJECT_NAME}\"\n",
        "os.makedirs(DRIVE_DIR, exist_ok=True)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if DEVICE == \"cuda\":\n",
        "    num_workers = 2\n",
        "    pin_memory = True\n",
        "    persistent = True\n",
        "else:\n",
        "    num_workers = 0\n",
        "    pin_memory = False\n",
        "    persistent = False\n",
        "ARCH = \"resnet50\"\n",
        "LR = 1e-3\n",
        "WD = 1e-4\n",
        "FREEZE_BACKBONE_EPOCHS = 1\n",
        "EPOCHS = 8\n",
        "\n",
        "if ARCH == \"resnet18\":\n",
        "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "    in_features = model.fc.in_features\n",
        "else:\n",
        "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "    in_features = model.fc.in_features\n",
        "\n",
        "model.fc = nn.Linear(in_features, len(class_names))\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(DEVICE))\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "if FREEZE_BACKBONE_EPOCHS > 0:\n",
        "    for name, p in model.named_parameters():\n",
        "        if not name.startswith(\"fc.\"):\n",
        "            p.requires_grad = False\n",
        "print(\"Device:\", DEVICE, \"| Backbone frozen for first\", FREEZE_BACKBONE_EPOCHS, \"epochs\")\n",
        "\n",
        "best_val_acc = 0.0\n",
        "history = {\"train_loss\":[], \"val_acc\":[]}\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} - train\"):\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    if epoch == FREEZE_BACKBONE_EPOCHS:\n",
        "        for p in model.parameters(): p.requires_grad = True\n",
        "        print(\"Unfroze backbone.\")\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0; total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch}/{EPOCHS} - val\"):\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    val_acc = correct / total if total>0 else 0.0\n",
        "    scheduler.step(val_acc)\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f}  val_acc={val_acc:.4f}\")\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), os.path.join(DRIVE_DIR, f\"best_{ARCH}.pth\"))\n",
        "        print(\"Saved new best model to Drive.\")\n",
        "\n",
        "print(\"Best val acc:\", best_val_acc)\n"
      ],
      "metadata": {
        "id": "6qrvjecg-AZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt, numpy as np, torch, os\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "\n",
        "plt.figure(); plt.plot(history[\"train_loss\"], label=\"train_loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Training Loss\"); plt.legend(); plt.savefig(os.path.join(DRIVE_DIR,\"training_loss.png\")); plt.show()\n",
        "plt.figure(); plt.plot(history[\"val_acc\"], label=\"val_acc\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Validation Accuracy\"); plt.legend(); plt.savefig(os.path.join(DRIVE_DIR,\"val_accuracy.png\")); plt.show()\n",
        "\n",
        "state_dict_path = os.path.join(DRIVE_DIR, f\"best_{ARCH}.pth\")\n",
        "model.load_state_dict(torch.load(state_dict_path, map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "all_labels, all_preds, all_probs = [], [], []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        outputs = model(images)\n",
        "        probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "        all_labels.extend(labels.numpy())\n",
        "        all_preds.extend(preds)\n",
        "        if len(class_names)==2:\n",
        "            all_probs.extend(probs[:,1])\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "import itertools\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation='nearest'); plt.title('Confusion matrix'); plt.colorbar()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names, rotation=45); plt.yticks(tick_marks, class_names)\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, f\"{cm[i,j]}\", ha=\"center\", va=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "plt.ylabel('True label'); plt.xlabel('Predicted label'); plt.tight_layout()\n",
        "plt.savefig(os.path.join(DRIVE_DIR, \"confusion_matrix.png\")); plt.show()\n",
        "\n",
        "if len(class_names)==2 and len(all_probs)==len(all_labels):\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
        "    print(\"ROC AUC:\", auc)\n",
        "    plt.figure(); plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\"); plt.plot([0,1],[0,1],'--'); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC Curve\"); plt.legend(loc=\"lower right\"); plt.savefig(os.path.join(DRIVE_DIR,\"roc_curve.png\")); plt.show()\n"
      ],
      "metadata": {
        "id": "u8un8KfA-FaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JDjeW0Q2ngyW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}